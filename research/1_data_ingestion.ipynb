{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca7a8a0",
   "metadata": {},
   "source": [
    "# Data Ingestion Pipeline Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b56cbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is G:\\ML_DL_Projects\\MLOPS_Indian_Flight_Price_Prediction \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# check the current working dir\n",
    "%pwd\n",
    "\n",
    "# changing the dir to main repo\n",
    "working_dir = \"G:/ML_DL_Projects/MLOPS_Indian_Flight_Price_Prediction\"\n",
    "os.chdir(working_dir)\n",
    "\n",
    "print(f\"Current working directory is {os.getcwd()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15a41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "# for src/<project_name>/entity/config_entity.py\n",
    "# step 1 in workflow for Data ingestion\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    root_dir : Path\n",
    "    source_URL : str\n",
    "    # kaggle_dataset : str\n",
    "    local_data_file : Path\n",
    "    unzip_dir : Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8968a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 and 3 not needed now\n",
    "# step 4 later on\n",
    "# step 5 in workflow for data ingestion\n",
    "\n",
    "# for src/<project_name>config/configuration.py\n",
    "from src.indian_flight_price_prediction.constants import *\n",
    "from src.indian_flight_price_prediction.utils.common import read_yaml, create_directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87884691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for src/<project_name>config/configuration.py\n",
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                config_file_path = CONFIG_FILE_PATH,\n",
    "                params_file_path = PARAMS_FILE_PATH,\n",
    "                schema_file_path = SCHEMA_FILE_PATH):\n",
    "        \n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        self.schema = read_yaml(schema_file_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            source_URL = config.source_URL,\n",
    "            local_data_file = config.local_data_file,\n",
    "            unzip_dir = config.unzip_dir\n",
    "        )\n",
    "        \n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aefdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for src/<project_name>/components/data_ingestion.py\n",
    "import os\n",
    "import urllib.request as request\n",
    "from src.indian_flight_price_prediction.logger import logger\n",
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2dc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compnent - Data Ingestion \n",
    "# for src/<project_name>/components/data_ingestion.py\n",
    "class DataIngestion:\n",
    "    def __init__(self, config : DataIngestionConfig):\n",
    "        self.config = config\n",
    "        # self.api = KaggleApi()\n",
    "        # self.api.authenticate()\n",
    "        \n",
    "        # to be added to the code \n",
    "        # try:\n",
    "        #     self.api.authenticate()\n",
    "        # except Exception as e:\n",
    "        #     raise RuntimeError(\"Failed to authenticate with Kaggle API\") from e\n",
    "    \n",
    "    # Downloading the zip file\n",
    "    def download_file(self):\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            filename, headers = request.urlretrieve(\n",
    "                url = self.config.source_URL,\n",
    "                filename = self.config.local_data_file\n",
    "            )\n",
    "            # dataset_name = self.config.kaggle_dataset\n",
    "            # logger.info(f\"Dataset {dataset_name} downloading!!\")\n",
    "            # self.api.dataset_download_files(\n",
    "            #     dataset = dataset_name,\n",
    "            #     path = os.path.dirname(self.config.local_data_file),\n",
    "            #     force = True,\n",
    "            #     quiet = False \n",
    "            # )\n",
    "            logger.info(f\"{filename} downloading with following info :\\n {headers}!!\")\n",
    "        else:\n",
    "            logger.info(f\"Dataset file already exists locally.\")\n",
    "\n",
    "    # extract zip file\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path : str\n",
    "        Extracts the zip file into the directory\n",
    "        \"\"\"\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok = True)\n",
    "        zip_file_path = self.config.local_data_file\n",
    "        # if not zip_file_path.endswith(\".zip\"):\n",
    "        #     zip_file_path += \".zip\"\n",
    "\n",
    "        with zipfile.ZipFile(zip_file_path, 'r' ) as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)\n",
    "            logger.info(f\"Data extracted to {unzip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e7fc939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-21 00:03:02,825 : INFO : common : yaml file : config\\config.yaml loaded successfully.]\n",
      "[2025-04-21 00:03:02,847 : INFO : common : yaml file : params.yaml loaded successfully.]\n",
      "[2025-04-21 00:03:02,860 : INFO : common : yaml file : schema.yaml loaded successfully.]\n",
      "[2025-04-21 00:03:02,873 : INFO : common : Created directory at artifacts]\n",
      "[2025-04-21 00:03:02,883 : INFO : common : Created directory at artifacts/data_ingestion]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-21 00:03:03,723 : INFO : 887415457 : artifacts/data_ingestion/data.zip downloading with following info :\n",
      " Connection: close\n",
      "Content-Length: 1514069\n",
      "Cache-Control: max-age=300\n",
      "Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox\n",
      "Content-Type: application/zip\n",
      "ETag: \"7bd18bccdb8b763b69796ea3f2f2c0926724b52a50f37715916a2b61b79007e5\"\n",
      "Strict-Transport-Security: max-age=31536000\n",
      "X-Content-Type-Options: nosniff\n",
      "X-Frame-Options: deny\n",
      "X-XSS-Protection: 1; mode=block\n",
      "X-GitHub-Request-Id: 1EDC:1442AC:30EE6D:8BC66A:68053DDB\n",
      "Accept-Ranges: bytes\n",
      "Date: Sun, 20 Apr 2025 18:33:04 GMT\n",
      "Via: 1.1 varnish\n",
      "X-Served-By: cache-bom4750-BOM\n",
      "X-Cache: MISS\n",
      "X-Cache-Hits: 0\n",
      "X-Timer: S1745173984.767185,VS0,VE570\n",
      "Vary: Authorization,Accept-Encoding,Origin\n",
      "Access-Control-Allow-Origin: *\n",
      "Cross-Origin-Resource-Policy: cross-origin\n",
      "X-Fastly-Request-ID: 392875e9d86117f09b817a927233b77aea17660f\n",
      "Expires: Sun, 20 Apr 2025 18:38:04 GMT\n",
      "Source-Age: 0\n",
      "\n",
      "!!]\n",
      "[2025-04-21 00:03:04,467 : INFO : 887415457 : Data extracted to artifacts/data_ingestion]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config = data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
